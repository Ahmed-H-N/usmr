<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Hypothesis testing</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);
e.style.display = ((e.style.display!='none') ? 'none' : 'block');
if(f.classList.contains('fa-plus')) {
    f.classList.add('fa-minus')
    f.classList.remove('fa-plus')
} else {
    f.classList.add('fa-plus')
    f.classList.remove('fa-minus')
}
}
</script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="assets/style-labs.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"><strong>USMR</strong></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
  </a>
</li>
<li>
  <a href="00_intro.html">Getting started</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Data &amp; Distributions
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="01_categorical.html">1: Categorical distributions</a>
    </li>
    <li>
      <a href="02_numerical.html">2: Numeric distributions</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Tests &amp; Models
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="03_nhst.html">3: Hypothesis testing</a>
    </li>
    <li>
      <a href="04_tests.html">4: More tests</a>
    </li>
    <li>
      <a href="05_covcor.html">5: Cov, Cor, Functions &amp; Models</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Regression
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="06_slr.html">6: Linear Regression Basics</a>
    </li>
    <li>
      <a href="07_mlr.html">7: More Regression</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Advanced topics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="08_contrasts.html">8: Contrasts</a>
    </li>
    <li>
      <a href="09_glm.html">9: GLM</a>
    </li>
    <li>
      <a href="10_everything.html">10: everything is an lm</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Hypothesis testing</h1>

</div>


<div class="red">
<p><strong>Preliminaries</strong></p>
<ol style="list-style-type: decimal">
<li>Open Rstudio, make sure you have the USMR project open, and create a new RMarkdown document (giving it a title for this week).</li>
</ol>
</div>
<div id="reading-standard-error" class="section level1">
<h1>Reading: Standard error</h1>
<p>Recall what we have seen thus far:</p>
<ul>
<li><p>We can generate a sample of size <span class="math inline">\(n\)</span>, drawn from a population which has a mean of <span class="math inline">\(\mu\)</span> and a standard deviation of <span class="math inline">\(\sigma\)</span>:</p>
<pre class="r"><code># draw random sample of n = 10 from 
# a population with mean 178 and sd 10
rnorm(n = 20, mean = 178, sd = 10)</code></pre></li>
<li><p>And we can calculate the mean of a random sample:</p>
<pre class="r"><code>mean(rnorm(n = 20, mean = 178, sd = 10))</code></pre>
<pre><code>## [1] 182.4367</code></pre></li>
<li><p>We can repeat this process many times (using <code>replicate()</code>), so that we have many sample means:</p>
<pre class="r"><code>manysamplemeans &lt;- replicate(1000, mean(rnorm(n = 20, mean = 178, sd = 10)))
# we now have 1000 sample means
length(manysamplemeans)</code></pre>
<pre><code>## [1] 1000</code></pre></li>
</ul>
<p><strong>Why are we doing this?</strong></p>
<p>What we’re doing here is showing the process of taking many samples of the same size from a population, and calculating a statistic on each sample.<br />
The distribution of these sample statistics shows how they will vary from sample to sample due to chance.</p>
<p>In the above example, for samples of <span class="math inline">\(n=20\)</span> drawn from a population with mean <span class="math inline">\(\mu=178\)</span>, and standard deviation <span class="math inline">\(\sigma=10\)</span>, we’re quite likely to get sample means between 174 and 182, and we’re less likely to see sample means <span class="math inline">\(&lt;174\)</span> and <span class="math inline">\(&gt;182\)</span>.</p>
<pre class="r"><code>hist(manysamplemeans)</code></pre>
<p><img src="03_nhst_files/figure-html/unnamed-chunk-4-1.png" width="384" style="display: block; margin: auto;" /></p>
<div class="yellow">
<ul>
<li>The theoretical distribution of how sample statistics will vary on repeated sampling is known as the <strong>sampling distribution</strong>.<br />
</li>
<li>The standard deviation of the sampling distribution is known as the <strong>standard error</strong>.<br />
</li>
<li>Note that the bigger our sample size, the smaller our standard error - i.e., the more precise our sample means are going to be as estimates of the population mean:
<img src="03_nhst_files/figure-html/unnamed-chunk-5-1.png" width="384" style="display: block; margin: auto;" /></li>
</ul>
</div>
<div id="standard-error-in-practice" class="section level2">
<h2>Standard Error in practice</h2>
<p>In practice, we cannot actually draw lots and lots of samples in order to construct a sampling distribution, and we do not know the population parameters which are required to generate samples like we did above.</p>
<p>Instead, we start with just one observed sample, e.g.:</p>
<pre class="r"><code>observed_sample &lt;- c(176.86, 169.45, 177.93, 175.89, 169.05, 162.56, 189.29, 196.15, 159.45, 165.69, 186.88, 176.9, 188.52, 164.05, 175.62, 180.89, 193.63, 161.59, 182.74, 184.23)</code></pre>
<p>What we <em>can</em> do is either:</p>
<ul>
<li><p><strong>A:</strong> Simulate lots of sampling. We can actually use <em>resampling with replacement</em> from our original sample as a means of imitating repeated sampling. This is known as <strong>Bootstrapping</strong>.</p>
<pre class="r"><code># bootstrap resample means
bootstrap_means &lt;- replicate(1000, mean(sample(observed_sample, replace = TRUE)))
# SE = sd of bootstrap resample means 
sd(bootstrap_means)</code></pre>
<pre><code>## [1] 2.452104</code></pre></li>
<li><p>or <strong>B:</strong> Estimate the standard error using a formula:<br />
<span class="math display">\[
SE = \frac{\sigma}{\sqrt{n}}  \\
\quad \\
\begin{align}
&amp; \text{Where} \\
&amp; \sigma = \text{standard deviation} \\
&amp; n = \text{sample size} \\
\end{align}
\]</span>
Note that <span class="math inline">\(\sigma\)</span> is the standard deviation of the population, which is unknown to us.<br />
However, we can use the standard deviation of our sample (<span class="math inline">\(\hat \sigma\)</span> or <span class="math inline">\(s\)</span>) as our estimate of this:</p>
<pre class="r"><code># SE = standard deviation / square root of n
sd(observed_sample)/sqrt(length(observed_sample))</code></pre>
<pre><code>## [1] 2.459404</code></pre></li>
</ul>
</div>
</div>
<div id="reading-hypothesis-testing" class="section level1">
<h1>Reading: Hypothesis testing</h1>
<p>The sampling distribution is at the basis of null hypothesis significance testing.</p>
<p>Recall from the previous lab that we had a dataset on 131 participants who took part in a Stroop Task experiment. Each participant completed a color-naming task in two conditions: Matching and Mismatching. The differences in participants’ times for each condition are taken as indicating the effect of the color-word inteference (we have been calling this the “stroop effect”).</p>
<p>In our observed sample, the stroop effect had a mean <span class="math inline">\(\bar x =\)</span> 2.4 and a standard deviation <span class="math inline">\(s=\)</span> 5.02.</p>
<p>We can theorise about what the sampling distribution of means from samples of size <span class="math inline">\(n=131\)</span> would be like, assuming there to be no stroop effect (i.e., the mean in the population is zero).</p>
<ul>
<li><p>We can estimate the standard error by generating many samples of size <span class="math inline">\(n=131\)</span>:</p>
<pre class="r"><code># bootstrap resample means:
many_stroop_means &lt;- replicate(1000, mean(sample(stroopdata$stroop_effect, replace = TRUE)))
# standard deviation of 1000 resample means
sd(many_stroop_means)</code></pre>
<pre><code>## [1] 0.4474773</code></pre></li>
<li><p>or we can estimate it by using the sample formula: <span class="math inline">\(\frac{\hat \sigma}{\sqrt{n}} = \frac{5.02}{\sqrt{131}} = 0.439\)</span>.</p></li>
</ul>
<p><br>
Either way, what we get is an idea of the distribution of what we would expect from means from samples of 131, under the hypothesis that there is no “stroop effect” - it will have a mean of 0 and a standard deviation of approximately 0.44.<br />
Against this, we can then compare our observed mean:</p>
<div class="figure" style="text-align: center"><span id="fig:hyp"></span>
<img src="03_nhst_files/figure-html/hyp-1.png" alt="Sampling distribution for mean of sample size 131, assuming population mean = 0. Observed sample mean shown in red" width="576" />
<p class="caption">
Figure 1: Sampling distribution for mean of sample size 131, assuming population mean = 0. Observed sample mean shown in red
</p>
</div>
<p>What we implicitly have here are two competing hypotheses: the null hypothesis (<span class="math inline">\(H_0\)</span>), and an alternative hypothesis (<span class="math inline">\(H_1\)</span>):</p>
<ul>
<li><span class="math inline">\(H_0: \mu = 0\)</span> The mean “stroop effect” in the population is equal to 0.<br />
</li>
<li><span class="math inline">\(H_1: \mu \neq 0\)</span> The mean “stroop effect” in the population is not equal to 0.</li>
</ul>
<p>We can do is perform a statistical test against the null hypothesis. Once we have defined our competing hypotheses (above), we decide on the appropriate test; calculate the test-statistic; and then compute the theoretical probability of results as or more extreme than those we observed.</p>
<div class="yellow">
<p><strong>Probability in NHST (null hypothesis significance testing)</strong></p>
<p>Probabilities in NHST are defined as the relative frequency of an event <em>over many trials</em> (as “many” <span class="math inline">\(\to \infty\)</span>).
This requires assuming some features of the data generating process which guides what the “many trials” would look like (e.g., that there is no effect).</p>
<p>A <span class="math inline">\(p\)</span>-value is the probability of observing results as or more extreme than the data, <em>if the data were really generated by a hypothesised chance process</em>.</p>
</div>
<div class="yellow">
<p><strong>Making decisions in NHST</strong></p>
<p>We pre-specify <span class="math inline">\(\alpha\)</span> (“alpha”) - the probability below which we will consider our results to be evidence against the null hypothesis.<br />
e.g.: setting <span class="math inline">\(\alpha = 0.05\)</span> means that if, <em>assuming the null hypothesis to be true</em> we would get a result at least as extreme as the one we observed only 0.05 (5%) of the time or less, then we will reject the null hypothesis.</p>
</div>
<div id="calculating-a-test-statistic" class="section level2">
<h2>Calculating a test statistic</h2>
<p>Performaing an hypothesis test requires calculating a <strong>test statistic</strong>.<br />
For our question (whether the mean stroop effect is different from 0), the appropriate test statistic is a <span class="math inline">\(t\)</span>-statistic, which is used to determine whether a sample mean <span class="math inline">\(\bar x\)</span> is likely to have been generated by a process with a specific theorised mean <span class="math inline">\(\mu_0\)</span>.</p>
<p><span class="math display">\[
t = \frac{\bar x - \mu_0}{\frac{s}{\sqrt{n}}}
\]</span></p>
<p>Think about what each part of the formula represents. The top part <span class="math inline">\(\bar{x}-\mu_0\)</span> is the distance from the observed mean to the hypothesised mean (zero):</p>
<pre class="r"><code>mean(stroopdata$stroop_effect) - 0</code></pre>
<pre><code>## [1] 2.402977</code></pre>
<p>And the bottom part is the standard error - the standard deviation of the sampling distribution:</p>
<pre class="r"><code># SE = sd / sqrt(n)
sd(stroopdata$stroop_effect) / sqrt(length(stroopdata$stroop_effect))</code></pre>
<pre><code>## [1] 0.4382302</code></pre>
<p><img src="03_nhst_files/figure-html/unnamed-chunk-13-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Let’s calculate the <span class="math inline">\(t\)</span>-statistic now:</p>
<pre class="r"><code>t_obs = (mean(stroopdata$stroop_effect) - 0 ) / (sd(stroopdata$stroop_effect)/sqrt(131))
t_obs</code></pre>
<pre><code>## [1] 5.483367</code></pre>
</div>
<div id="computing-the-p-value" class="section level2">
<h2>Computing the p-value</h2>
<p>Now that we have our test statistic, we are able to ask the following question:</p>
<ul>
<li>Assuming the null hypothesis <span class="math inline">\(H_0\)</span> to be true, what is the probability that we observe a test statistic at least as extreme as the one we observed?</li>
</ul>
<p>The sampling distribution of a <span class="math inline">\(t\)</span>-statistic (i.e., the distribution of <span class="math inline">\(t\)</span>-statistics from many many trials) follows a <span class="math inline">\(t\)</span>-distribution. The particular shape of the <span class="math inline">\(t\)</span>-distribution is determined by the <strong>degrees of freedom</strong>. By ‘degrees of freedom’ we refer to the number of independent observations in a set of data.</p>
<p>When we are estimating a mean from a single sample, the degrees of freedom is equal to the sample size minus one. This means that the sampling distribution of <span class="math inline">\(t\)</span>-statistics from samples of size 10, would follow a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(10-1\)</span> degrees of freedom.</p>
<p>You can see the <span class="math inline">\(t\)</span>-distribution for different degrees of freedom below. Notice that as the degrees of freedom (<span class="math inline">\(\nu\)</span> in the plot below) gets bigger (so as <span class="math inline">\(n\)</span> gets bigger), the more the <span class="math inline">\(t\)</span>-distibution fits a normal distribution.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-15"></span>
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Student_t_pdf.svg/1024px-Student_t_pdf.svg.png" alt="t distributions. Source: https://en.wikipedia.org/wiki/Student%27s_t-distribution" width="400px" height="300px" />
<p class="caption">
Figure 2: t distributions. Source: <a href="https://en.wikipedia.org/wiki/Student%27s_t-distribution" class="uri">https://en.wikipedia.org/wiki/Student%27s_t-distribution</a>
</p>
</div>
<div class="optional-begin">
Degrees of freedom (df)<span id="opt-start-37" class="fa fa-plus optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-37&#39;, &#39;opt-start-37&#39;)"></span>
</div>
<div id="opt-body-37" class="optional-body" style="display: none;">
<p>Suppose we have four unkown numbers (<span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, <span class="math inline">\(c\)</span> and <span class="math inline">\(d\)</span>) which <em>must</em> have a mean of 5.</p>
<p>Do the following, <em>in order:</em></p>
<ol style="list-style-type: decimal">
<li>Choose a value for <span class="math inline">\(a\)</span>.</li>
<li>Choose a value for <span class="math inline">\(b\)</span>.</li>
<li>Choose a value for <span class="math inline">\(c\)</span>.</li>
<li>Can you choose a value for <span class="math inline">\(d\)</span> while ensuring the mean of the four numbers you have chosen is 5?</li>
</ol>
<hr />
<p>You a free to choose anything you like for <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span> and <span class="math inline">\(c\)</span>.<br />
But once those are fixed, you have no freedom to choose <span class="math inline">\(d\)</span>.</p>
<p>Example:</p>
<ul>
<li><span class="math inline">\(a\)</span> = 1<br />
</li>
<li><span class="math inline">\(b\)</span> = 2<br />
</li>
<li><span class="math inline">\(c\)</span> = 3</li>
</ul>
<p>We know that <span class="math inline">\(\frac{1+2+3+d}{4} = 5\)</span>
So there is only one possible value for <span class="math inline">\(d\)</span>:<br />
<span class="math inline">\(\frac{1+2+3+d}{4} = 5\)</span><br />
<span class="math inline">\(1+2+3+d = 5*4\)</span><br />
<span class="math inline">\(1+2+3+d = 20\)</span><br />
<span class="math inline">\(d = 20-3-2-1\)</span><br />
<span class="math inline">\(d = 14\)</span></p>
</div>
<p class="optional-end">
</p>
<p>We can ask R to calculate what proportion of the <span class="math inline">\(t\)</span>-distribution with 130 (<span class="math inline">\(131-1\)</span>) degrees of freedom is more extreme than the <span class="math inline">\(t\)</span>-statistic we observed.</p>
<pre class="r"><code># our t statistic:
t_obs</code></pre>
<pre><code>## [1] 5.483367</code></pre>
<pre class="r"><code># proportion of distribution to the right
pt(t_obs, df = 130, lower.tail = FALSE)</code></pre>
<pre><code>## [1] 1.046221e-07</code></pre>
<p>As you can see, the resulting value is very small. This tells us that if there is truly no stroop effect, and we took lots and lots of samples of 131 peoples’ responses and calculated a <span class="math inline">\(t\)</span>-statistic for each one of them, then <span class="math inline">\(1.0462207\times 10^{-7}\)</span> of the time we will get a <span class="math inline">\(t\)</span>-statistic <span class="math inline">\(&gt;\)</span> 5.48.</p>
<p>Recall, however, that our alternative hypothesis is that the mean is <strong>not equal</strong> to 0. This means we will reject the null hypothesis if we find a strong stroop effect <em>in either direction</em>.<br />
So we therefore want to calculate the probability of getting a <span class="math inline">\(t\)</span>-statistic as extreme as the one observed <em>in either direction</em>. Because the <span class="math inline">\(t\)</span>-distribution is symmetrical, we can simply multiply the previous bit of code by 2.</p>
<pre class="r"><code>pt(t_obs, df = 130, lower.tail = FALSE) * 2</code></pre>
<pre><code>## [1] 2.092441e-07</code></pre>
<div class="int">
<p>If the null hypothesis were true (the mean stroop effect in the population is zero), then 0.000000209 of random samples of size <span class="math inline">\(n=131\)</span> would result in a <span class="math inline">\(t\)</span>-statistic which is at least as extreme as the one we observed (<span class="math inline">\(\geq 5.48\)</span> or <span class="math inline">\(\leq -5.48\)</span>).</p>
<p>Given that this is less than our pre-specified level (0.05), we will take this as reason to reject the null hypothesis.</p>
</div>
</div>
<div id="letting-r-do-all-the-work" class="section level2">
<h2>Letting R do all the work</h2>
<p>The good news is that we can do all of this without having to go through the rigmarole of manually calculating the test-statistic or computing the p-value.</p>
<p>Pay attention to how the parts of the results of the below match up with our calculations above.</p>
<pre class="r"><code>t.test(stroopdata$stroop_effect, mu = 0)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  stroopdata$stroop_effect
## t = 5.4834, df = 130, p-value = 2.092e-07
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  1.535991 3.269963
## sample estimates:
## mean of x 
##  2.402977</code></pre>
<!-- ```{r echo=FALSE, fig.width=6, fig.height=4} -->
<!-- ggplot(data=tibble(samplemeans),aes(x=samplemeans))+ -->
<!--   geom_histogram(col="white", alpha=.1)+ -->
<!--   stat_function(geom="line",fun=~dnorm(.x, mean=0,sd=sd(samplemeans))*250,lwd=1)+ -->
<!--   geom_vline(aes(xintercept=0.7),lty="dashed",col="tomato1")+ -->
<!--   geom_vline(aes(xintercept=0),lty="dashed")+ -->
<!--   ylim(0,300)+ -->
<!--   labs(x = "mean stroop effect")+ -->
<!--   scale_y_continuous(NULL, breaks=NULL)+ -->
<!--   scale_x_continuous(NULL, breaks=NULL)+ -->
<!--   theme_minimal()+ -->
<!--   annotate("text",x=.3, y=125, label = expression(bar(x)-0), col="tomato1")+ -->
<!--   geom_segment(aes(x=0, xend=0.7, y=120, yend=120), col="tomato1", size=0.5, arrow = arrow(length = unit(0.03, "npc"),ends="both")) +  -->
<!--   geom_segment(aes(x=0, xend=sd(samplemeans), y=20, yend=20), col="tomato1", size=0.5)+ -->
<!--   annotate("text",x=1.12, y=50, label = expression(s/sqrt(n)), col="tomato1")+ -->
<!--   geom_curve(aes(x=1, xend=sd(samplemeans)-.1, y=50, yend=22), col="grey30", size=0.5, curvature = 0.2, arrow = arrow(length = unit(0.03, "npc"))) -->
<!-- ``` -->
</div>
<div id="tests-have-assumptions" class="section level2">
<h2>Tests have assumptions</h2>
<p>Conducting hypothesis tests entails holding certain assumptions, for instance that the observed sample has been drawn at random from the population of interest.</p>
<p>For the test we just performed we also require the assumption that the data are drawn from a normally distributed population.
In order to assess whether we have any evidence to reject this assumption, we can plot the data:</p>
<pre class="r"><code>plot(density(stroopdata$stroop_effect))
qqnorm(stroopdata$stroop_effect)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-20"></span>
<img src="03_nhst_files/figure-html/unnamed-chunk-20-1.png" alt="Stroop effect data: Density curve (normality is when curve is bell-shaped and symmetric), and Quantile-Quantile plot (normality is when lines fall on a straight diagonal)" width="672" />
<p class="caption">
Figure 3: Stroop effect data: Density curve (normality is when curve is bell-shaped and symmetric), and Quantile-Quantile plot (normality is when lines fall on a straight diagonal)
</p>
</div>
<p>And we can also perform a hypothesis test against the null hypothesis that the data is drawn from a normally distributed population. <strong>Note</strong> that if the <span class="math inline">\(p\)</span>-value of this test is below our specified <span class="math inline">\(\alpha\)</span>, we have evidence that this assumption is violated (because the null hypothesis is our assumption)</p>
<pre class="r"><code>shapiro.test(stroopdata$stroop_effect)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  stroopdata$stroop_effect
## W = 0.9897, p-value = 0.4417</code></pre>
<p>Because <span class="math inline">\(p\)</span>&gt;.05, we fail to reject the null hypothesis of the Shapiro-Wilk test that the sample came from a population that is normally distributed.</p>
<div class="int">
<p>Shapiro-Wilk test did not indicate violation of the assumption of normality (<span class="math inline">\(W\)</span>=0.99, <span class="math inline">\(p\)</span>=0.442).</p>
</div>
</div>
</div>
<div id="exercises-some-simple-tests" class="section level1">
<h1>Exercises: Some simple tests</h1>
<div class="question-begin">
Question 1
</div>
<div class="question-body">
<p>The Procrastination Assessment Scale for Students (PASS) was designed to assess how individuals approach decision situations, specifically the tendency of individuals to postpone decisions (see <a href="http://dx.doi.org/10.1037/0022-0167.31.4.503">Solomon &amp; Rothblum, 1984</a>).</p>
<p>The PASS assesses the prevalence of procrastination in six areas: writing a paper; studying for an exam; keeping up with reading; administrative tasks; attending meetings; and performing general tasks.
For a measure of total endorsement of procrastination, responses to 18 questions (each measured on a 1-5 scale) are summed together, providing a single score for each participant (range 0 to 90).
The mean score from Solomon &amp; Rothblum, 1984 was 33.</p>
<blockquote>
<p><strong>Research Question</strong>
Do Edinburgh University students report endorsing procrastination less than the norm?</p>
</blockquote>
<p>A student has administered the PASS to 20 students from Edinburgh University. The data is available at <a href="https://edin.ac/2wJgYwL">https://edin.ac/2wJgYwL</a>.</p>
<p>Conduct a one sample <span class="math inline">\(t\)</span>-test to evaluate whether Edinburgh University students’ average score on the PASS is not equal to 33. Remember to check the assumptions!</p>
<p><strong>Note:</strong> Think carefully about the wording of the question. Is the alternative hypothesis “less than”, “greater than” or “not equal to”? What does this mean in relation to the areas of the <span class="math inline">\(t\)</span>-distribution for which you will reject the null hypothesis - upper tail, lower tail, or both tails? Check out the help page for <code>t.test()</code> - is there some thing you can change to make sure it is the correct option?</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-38" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-38&#39;, &#39;sol-start-38&#39;)"></span>
</div>
<div id="sol-body-38" class="solution-body" style="display: none;">
<pre class="r"><code>pass_scores &lt;- read_csv(&quot;https://edin.ac/2wJgYwL&quot;) 

ggplot(data = pass_scores, aes(x=PASS)) + 
  geom_boxplot()</code></pre>
<p><img src="03_nhst_files/figure-html/unnamed-chunk-22-1.png" width="480" style="display: block; margin: auto;" /></p>
<pre class="r"><code>shapiro.test(pass_scores$PASS)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  pass_scores$PASS
## W = 0.93617, p-value = 0.2028</code></pre>
<pre class="r"><code>t.test(pass_scores$PASS, mu = 33, alternative = &quot;less&quot;)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  pass_scores$PASS
## t = -3.1073, df = 19, p-value = 0.0029
## alternative hypothesis: true mean is less than 33
## 95 percent confidence interval:
##     -Inf 31.9799
## sample estimates:
## mean of x 
##      30.7</code></pre>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question
</div>
<div class="question-body">
<p>Write up the results.</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-39" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-39&#39;, &#39;sol-start-39&#39;)"></span>
</div>
<div id="sol-body-39" class="solution-body" style="display: none;">
<div class="int">
<p>A one-sided one-sample t-test was conducted in order to determine if the average score on the Procrastination Assessment Scale for Students (PASS) for a sample of 20 students at Edinburgh University was significantly lower (<span class="math inline">\(\alpha = .05\)</span>) than the average score obtained during development of the PASS.</p>
<p>Edinburgh University students scored lower (Mean=30.7, SD=3.31) than the score reported by the authors of the PASS (Mean = 33). This difference was statistically significant (t(19)=-3.11, p &lt; .05, one-tailed).</p>
</div>
</div>
<p class="solution-end">
</p>
<div id="independent-samples-t-test" class="section level2">
<h2>independent samples t test</h2>
</div>
<div id="chi-square-test" class="section level2">
<h2>chi square test</h2>
<p>table, fill it by hand
calculate chisq
pchisq
check using</p>
</div>
</div>
<div id="exercises-writing-results-in-rmarkdown" class="section level1">
<h1>Exercises: Writing results in Rmarkdown</h1>
<p>For the results of a <span class="math inline">\(t\)</span>-test, we can write our results like this:</p>
<div class="frame">
<p><img src="images/hypothesis/rmarkdownbacktick.png" width="1000px" style="display: block; margin: auto;" /></p>
</div>
<p>In order for them to be compiled like this:</p>
<div class="frame">
<p>A one-sided one-sample t-test was conducted in order to determine if the average score on the Procrastination Assessment Scale for Students (PASS) for a sample of 20 students at Edinburgh University was significantly lower (<span class="math inline">\(\alpha = .05\)</span>) than the average score obtained during development of the PASS.</p>
<p>Edinburgh University students scored lower (Mean = 30.7, SD = 3.31) than the score reported by the authors of the PASS (Mean = 33). This difference was statistically significant (t(19)=-3.11, p &lt; .05, one-tailed).</p>
</div>
<p>This is one of the huge benefits of RMarkdown. Imagine we collected more data - we wouldn’t have to edit all the results, we could simply recompile and they would update for us!<br />
Note how it works:</p>
<ul>
<li>the code chunk saves the results of the <code>t.test()</code> function as a named object <code>res2</code>.</li>
<li>in text, the backticks <code>`r … … … `</code> are used to execute small bits of R code, and include the output within the text. For instance, the line <code>`r res2$statistic %&gt;% round(2)`</code> gets the t-statistic from the results, and rounds it to 2 decimal places, which get’s printed out as -3.11.</li>
</ul>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
