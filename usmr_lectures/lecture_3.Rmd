---
title: "<b>Week 3: Testing Statistical Hypotheses</b>"
subtitle: "Univariate Statistics and Methodology using R"
author: "Martin Corley"
institute: "Department of Psychology<br/>The University of Edinburgh"
date: "AY 2020-2021"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: 
      - xaringan-themer.css
      - mc_libs/tweaks.css
    nature:
      beforeInit: "mc_libs/macros.js"
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
editor_options:
  chunk_output_type: console
---


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
options(digits=4,scipen=2)
options(knitr.table.format="html")
xaringanExtra::use_xaringan_extra(c("tile_view","animate_css","tachyons"))
xaringanExtra::use_extra_styles(
  mute_unhighlighted_code = FALSE
)
library(knitr)
library(tidyverse)
library(ggplot2)
source('R/pres_theme.R')
knitr::opts_chunk$set(
  dev = "svg",
  warning = FALSE,
  message = FALSE,
  cache = TRUE
)
source('R/myfuncs.R')
```

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
style_mono_accent(
  #base_color = "#0F4C81", # DAPR1
  # base_color = "#BF1932", # DAPR2
  # base_color = "#88B04B", # DAPR3 
  base_color = "#FCBB06", # USMR
  # base_color = "#a41ae4", # MSMR
  header_color = "#000000",
  header_font_google = google_font("Source Sans Pro"),
  header_font_weight = 400,
  text_font_google = google_font("Source Sans Pro", "400", "400i", "600", "600i"),
  code_font_google = google_font("Source Code Pro")
)
```

class: inverse, center, middle

# Part 1

---
# More about Height

.pull-left[
- last time we simulated the heights op a population of 10,000 people

- mean height ( $\bar{x}$ ) was 170; standard deviation ( $\sigma$ ) was 12.
  
```{r pop, fig.asp=.6}
curve(dnorm(x,170,12),from = 120, to = 220)
```
]
.pull-right[
.center[
![:scale 70%](lecture_3_files/img/playmo_tms.jpg)
]]


---
# How Unusual is Casper?


.pull-left[
- in his socks, Casper is 198 cm tall

- how likely would we be to find someone Casper's height in our population?
]
.pull-right[
```{r normvline,echo=FALSE, fig.asp=.6}
t <- tibble(x=c(120,220))
p <- t %>% ggplot(aes(x=x)) +
  stat_function(fun=dnorm,n=151,args=list(mean=170,sd=12),size=1.5) +
  xlab("height") + ylab("density")
p + geom_vline(xintercept=198,colour="red")
```
]
???
- we can mark Casper's height on our normal curve
- but we can't do anything with this information
  + technically the line has "no width" so we can't calculate area
  + we need to reformulate the question
---
# How Unusual is Casper (Take 2)?

.pull-left[
- in his socks, Casper is 198 cm tall

- how likely would we be to find someone Casper's height _or more_ in our population?
]
.pull-right[
```{r normarea,echo=FALSE, fig.asp=.6}
ld <- layer_data(p) %>% filter(x >= 198)
q<- p + geom_area(data=ld,aes(x=x,y=y),fill="red") +
  stat_function(fun=dnorm,n=151,args=list(mean=170,sd=12),size=1.5)
q  
```
]


---
count: false
# How Unusual is Casper (Take 2)?

.pull-left[
- in his socks, Casper is 198 cm tall

- how likely would we be to find someone Casper's height _or more_ in our population?

- the area is `r (pp=pnorm(198,170,12,lower.tail=F))`

- so the probability of finding someone in the population of Casper's height or greater is `r pp` (or, $p=`r pp`$ )
]
.pull-right[
```{r normarea2,echo=FALSE, fig.asp=.6}
q
```
]

---
# Area under the Curve

.pull-left[
- so now we know that the area under the curve can be used to quantify **probability**

- but how do we calculate area under the curve?

- luckily, R has us covered, using (in this case) the `pnorm()` function

```{r pnorm}
pnorm(198, mean = 170, sd=12,
      lower.tail = FALSE)
```

]
.pull-right[
```{r tails, echo=F, fig.asp=.6}
df <- data.frame(lx=200,rx=196,lxe=215,rxe=181,y=.025)
p + geom_vline(xintercept=198,colour="red") +
  geom_segment(data=df,aes(x=lx,y=y,xend=lxe,yend=y),arrow=arrow(unit(35,"npc")),colour="red") +
  annotate(geom="text",x=df$lx+10,y=.028,label="upper tail",size=6,colour="red") + geom_segment(data=df,aes(x=rx,y=y,xend=rxe,yend=y),arrow=arrow(unit(35,"npc")),colour="red") +
  annotate(geom="text",x=df$rx-10,y=.028,label="lower tail",size=6,colour="red")

```

]
---
# Tailedness

.pull-left[
- we kind of knew that Casper was _tall_
  + it made sense to ask what the likelihood of finding someone 198 cm _or greater_ was
    + this is called a **one-tailed hypothesis** (we're not expecting Casper to be well below average height!)
  
- often our hypothesis might be vaguer
  + we expect Casper to be "different", but we're not sure how
    + we can capture this using a **two-tailed hypothesis**
]
.pull-right[
```{r normtwo, echo=F,fig.asp=.6}
ld <- layer_data(p) %>% filter(x <= 142)
q + geom_area(data=ld,aes(x=x,y=y),fill="red") +
  stat_function(fun=dnorm,n=151,args=list(mean=170,sd=12),size=1.5) +
  geom_vline(xintercept = 170) + 
  annotate(geom="text",colour="red",x=175,y=.015,label="mean")
```
]

---
count: false

# Tailedness

.pull-left[
- we kind of knew that Casper was _tall_
  + it made sense to ask what the likelihood of finding someone 198 cm _or greater_ was
    + this is called a **one-tailed hypothesis** (we're not expecting Casper to be well below average height!)
  
- often our hypothesis might be vaguer
  + we expect Casper to be "different", but we're not sure how
    + we can capture this using a **two-tailed hypothesis**
]
.pull-right[
- for a two-tailed hypothesis we need to sum the relevant upper and lower areas

- since the normal curve is symmetrical, this is easy!

```{r twot}
2 * pnorm(198, 170, 12, lower.tail = FALSE)
```


]

---
# So: Is Casper Special?

- how surprised should we be that Casper is 198 cm tall?

- given the population he's in, the probability that he's 28cm or more taller than the mean of 170 is `r (pp=pnorm(198,170,12,lower.tail=FALSE))` 
  + NB., this is according to a _one-tailed hypothesis_
  
--

- a more accurate way of saying this is that `r pp` is the probability of selecting him (or someone even taller than him) from the population at random

---
# A Judgement Call

.pull-left[
- if a `r (pc=round(100*pp,0))`% probability is _small enough_
.center[
![:scale 55%](lecture_3_files/img/playmo_good.jpg)
]]
???
if a `r pc`% probability of selecting someone 28cm or more above the mean is enough to surprise us, then we should be surprised

if, on the other hand, we think `r pc`% isn't particularly low, then we shouldn't be surprised
--

.pull-right[
.center[
- if a `r pc`% chance doesn't impress us much
.center[
![:scale 55%](lecture_3_files/img/playmo_bad.jpg)
]]

]

- in either case, we have nothing (mathematical) to say about the _reasons_ for Casper's height

???
when it comes to comparing means, we'll see that there are conventions for the criteria we use, but they are just that:  conventions, because this is a judgement call.

And importantly, none of the maths we have done will tell us anything about the _reasons_ for Casper's height&mdash;that's for us to reason about.

Perhaps he's so tall because he's weightless, or perhaps he had a lot of milk in his diet:  That's the substance of the scientific paper we're going to write:  The statistical calculation just tells us that he's mildly unusual.

In the next part, we're going to look at how this works for group means as opposed to individuals, but the TL;DR is:  pretty much the same.

---
class: inverse, center, middle, animated, rubberBand

# End of Part 1

---
class: inverse, center, middle

# Part Two

### Group Means

---
# Investment Strategies

.br3.pa2.pt2.bg-gray.white.f3[
The Playmo Investors' Circle have been pursuing a special investment strategy over the past year.  By no means everyone has made a profit.  Is the strategy worth advertising to others?
]

```{r invest, echo=F, fig.asp=.2, fig.width=11}
set.seed(25)
m <- tibble(profit=rnorm(12,20,20),color=if_else(profit <0,'A','B'),
            names=c('Adam','Bill','Clare','Dave','Emma','Fred','Gina','Hal','Ian','Jane','Kim','Leo'))
m %>% ggplot(aes(x=names,y=profit,fill=color)) +
  geom_bar(stat="identity") +
  scale_fill_manual(values=c("red","blue")) +
  theme_presentation(10) +
  theme(legend.position = "none", axis.text.x = element_text(angle=45)) +
  xlab("") + ylab("£ profit")
profit <- m$profit

```
---
# Information About the Investments

.pull-left[
- there are 12 investors

- the mean profit is £`r (pr=round(mean(profit),2))`

- the standard deviation is £`r round(sd(profit),2)`

- the standard error is $\sigma/\sqrt{12}$ which is `r sd(profit)/sqrt(12)`

.pt2[
- we are interested in the _probability of 12 people making at least a mean £`r pr` profit_

  + assuming that they come from the same population
]]

.pull-right[
![:scale 70%](lecture_3_files/img/playmo_investors.jpg)
]

---
# Using Standard Error

.pull-left[
- together with the mean, the standard error describes a normal distribution

- "likely distribution of means for other samples of 12"
]

.pull-right[
```{r segraph, echo=FALSE, fig.asp=.6}
df <- tibble(x=c(-30,30))
df %>% ggplot(aes(x=x)) +
  stat_function(fun=dnorm,n=151,args=list(mean=mean(profit),sd=sd(profit)/sqrt(12)),size=2) +
  geom_vline(xintercept=mean(profit),colour="red") +
  xlab("mean profit") + ylab("density")
```
]

---
# Using Standard Error (2)

.pull-left[
- last time, our **null hypothesis** ("most likely outcome") was "Casper is of average height"

- this time, our null hypothesis is "there was no profit"

- easiest way to operationalize this:

  + "the average profit was zero"
  
- so redraw the normal curve with _the same standard error_ and a _mean of zero_
]

.pull-right[
```{r segraph2, echo=FALSE, fig.asp=.6}
ng <- df %>% ggplot(aes(x=x)) +
  stat_function(fun=dnorm,n=151,args=list(mean=mean(profit),sd=sd(profit)/sqrt(12)),size=1.5,colour="grey") +
  xlab("mean profit") + ylab("density") +
  stat_function(fun=dnorm,n=151,args=list(mean=0,sd=sd(profit)/sqrt(12)),size=2)+
  geom_vline(xintercept=mean(profit),colour="red") +
  geom_vline(xintercept=0,linetype=3)
ng
```
]

---
# Using Standard Error (3)

.pull-left[
- null hypothesis: $\mu=0$

- probability of making a mean profit of £`r pr` or more:

  + _one-tailed_ hypothesis
  
  + evaluated as relevant area under the curve
  
```{r area}
se=sd(profit)/sqrt(12)

pnorm(mean(profit), mean=0, sd=se,
      lower.tail=FALSE)
```
]

.pull-right[
```{r segraph3, echo=FALSE, fig.asp=.6}
ld <- layer_data(ng,2) %>% filter(x>=mean(profit))
ng + geom_area(data=ld,aes(x=x,y=y),fill="red") +
    stat_function(fun=dnorm,n=151,args=list(mean=0,sd=sd(profit)/sqrt(12)),size=2)
```
]

---
# The Standardized Version

.flex.items-center[
.w-60[
- last week we talked about the _standard normal curve_
  + mean = 0; standard deviation = 1
- our investors' curve is very easy to transform
  + mean is _already_ 0; divide by standard error  
```{r twopnorms}
pnorm(mean(profit),0,se,lower.tail=FALSE)
pnorm(mean(profit)/se,0,1,lower.tail=FALSE)
```
- `mean(profit)/se` (`r mean(profit)/se`) is "number of standard errors from zero"
]
.w-40.pa2[
```{r snc,echo=FALSE, fig.asp=.6}
df <- tibble(x=c(-3.5,3.5))
gr <- df %>% ggplot(aes(x=x)) +
  stat_function(fun=dnorm,n=451,size=2) +
  xlab("standard errors") +
  ylab("density") +
  geom_vline(xintercept=mean(profit)/se,colour="red") +
  annotate(geom="text",x=mean(profit)/se-1,y=.28,label=paste0(round(mean(profit)/se,2)," standard errors"),size=6,colour="red")
ld <- layer_data(gr) %>% filter(x >= mean(profit)/se)
gr + geom_area(data=ld,aes(x=x,y=y),fill="red") +
  stat_function(fun=dnorm,n=451,size=2)
```

]]
---
# The Standardised Version

- you can take _any_ mean, and _any_ standard deviation, and produce "number of standard errors from the mean"

  + $z=\bar{x}/\sigma$
  
- here, the standard deviation is a _standard error_, but needn't be

  + the point of the calculation is to compare to the **standard normal curve**
  
  + made "looking up probability" easier in the days of printed tables
 
--

- usual practice is to refer to standardised statistics

  + _the name chosen for them comes from the relevant distribution_
  
- $z$ is assessed using the normal distribution
---
# Which Means...
- for $z=`r mean(profit)/se`$, $p=`r pnorm(mean(profit/se),lower.tail=FALSE)`$

.br3.pa2.pt2.bg-gray.white.f3[
If you picked 12 people at random from a population of investors who were making no profit, there would be a `r (pc=round(100*pnorm(mean(profit),0,sd(profit)/sqrt(12),lower.tail=F),0))`% chance that their average profit would be £`r pr` or more.
]

.pt2[
- is `r pc`% low enough for you to believe that the mean profit probably wasn't due to chance?

  + again, it's a _judgement call_
  
  + but before we make that judgement...
]
???
obviously here our "population of investors" means "investors like the Playmo Investors' Circle.

One important thing about statistics is that you can only extrapolate to the relevant population (but it's a matter of interpretation what the relevant population is!)
---
class: inverse, middle, center, animated, rubberBand

# End of Part 2

---
class: inverse, middle, center

# Part 3

### The $t$-test

---
# A Small Confession

.pull-left[
![:scale 70%](lecture_3_files/img/playmo_liar.jpg)
]

.pull-right[
### Part Two wasn't entirely true

- all of the principles are correct, but for smaller $n$ the normal curve isn't the best estimate

- for that we use the $t$ distribution
]


---
# The $t$ Distribution

.pull-left[
.center[
![:scale 40%](lecture_3_files/img/gossett.jpg)

"A. Student", or William Sealy Gossett
]]

.pull-right[
```{r normvst, echo=F, fig.asp=.6}
df <- tibble(x=c(-3.5,3.5))
df %>% ggplot(aes(x=x)) +
  stat_function(fun=dnorm,n=151,colour="grey") +
  stat_function(fun=dt,n=151,args=list(df=11),colour="red") +
  xlab("standard deviations") + ylab("density") +
  annotate(geom="text",x=1.7,y=.3,label="t(11)",colour="red",size=8)
```

]

???
The official name for the $t$-distribution is "Student's t-distribution", after William Gossett's pen-name

Gossett specialised in statistics for relatively small numbers of observations, working with Pearson, Fisher, and others

---
- the "11" is the degrees of freedom (size of the sample-1)

---
class: inverse, center, middle, animated, rubberBand

# End

---
# Acknowledgements

- icons by Diego Lavecchia from the [Noun Project](https://thenounproject.com/)